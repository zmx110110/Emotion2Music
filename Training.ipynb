{"cells":[{"cell_type":"markdown","metadata":{"gradient":{"editing":false,"id":"fa0a611c-1803-42ae-bdf6-a49b5a4e781b","kernelId":""},"id":"gOd93yV0sGd2"},"source":["# 一、运行环境设置"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"editing":false,"id":"39411b40-9e39-416e-8fe4-d40f733e7956","kernelId":""},"id":"lw-4aqV3sKQG"},"outputs":[],"source":["#@title 检测GPU\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"editing":false,"id":"a1a45a91-d909-4fd4-b67a-5e16b971d179","kernelId":""},"id":"fX12Yquyuihc"},"outputs":[],"source":["# 安装依赖\n","# 下载源码\n","!git clone https://github.com/zmx110110/Emotion2Music\n","!pip install torch\n","!pip install tqdm\n","!pip install matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"editing":false,"id":"b8207b76-9514-4c07-95db-95a4742e52c5","kernelId":""},"id":"z7n9vnKmug1J"},"outputs":[],"source":["#@title 导入相关库\n","\n","print('Loading needed modules. Please wait...')\n","import os\n","from tqdm import tqdm\n","import random\n","import secrets\n","\n","if not os.path.exists('/content/Emotion2Music/Dataset'):\n","    os.makedirs('/content/Emotion2Music/Dataset')\n","\n","if not os.path.exists('/content/Emotion2Music/INTS'):\n","    os.makedirs('/content/Emotion2Music/INTS')\n","\n","print('Loading TMIDIX and GPT2RGAX modules...')\n","os.chdir('/content/Emotion2Music')\n","import TMIDIX\n","from GPT2RGAX import *\n","\n","import matplotlib.pyplot as plt\n","\n","os.chdir('/content/Emotion2Music')"]},{"cell_type":"markdown","metadata":{"gradient":{"editing":false,"id":"20b8698a-0b4e-4fdb-ae49-24d063782e77","kernelId":""},"id":"ObPxlEutsQBj"},"source":["# 二、数据集准备"]},{"cell_type":"markdown","source":["### 下载MMD数据集，并将其解压到/Dataset 目录\n","\n","https://github.com/jeffreyjohnens/MetaMIDIDataset"],"metadata":{"id":"IID1-w0wldhy"}},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"editing":false,"id":"ffbb7a2a-d91a-477f-ac89-56d77d6cdf42","kernelId":""},"id":"snIZ3xKPsPgB"},"outputs":[],"source":["#@title 下载数据集，居于MuseGan的全音轨数据集进行训练，包含五种乐器。\n","\n","%cd /content/Emotion2Music/Dataset/\n","\n","!wget 'http://hog.ee.columbia.edu/craffel/lmd/lmd_full.tar.gz'\n","!tar -xvf 'lmd_full.tar.gz'\n","!rm 'lmd_full.tar.gz'\n","\n","%cd /content/Emotion2Music"]},{"cell_type":"markdown","source":["# 数据预处理"],"metadata":{"id":"JwrqQeie08t0"}},{"cell_type":"markdown","source":["### 由于数据集的巨大规模，处理将分块进行"],"metadata":{"id":"PjSzq-QTmuD9"}},{"cell_type":"code","source":["#@title 扫描/数据集目录/MDI文件并保存文件列表以防万一\n","###########\n","print('Loading MIDI files...')\n","print('This may take a while on a large dataset in particular.')\n","\n","dataset_addr = \"/content/Emotion2Music/Dataset\"\n","# os.chdir(dataset_addr)\n","filez = list()\n","for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n","    filez += [os.path.join(dirpath, file) for file in filenames]\n","print('=' * 70)\n","\n","if filez == []:\n","    print('Could not find any MIDI files. Please check Dataset dir...')\n","    print('=' * 70)\n","\n","print('Randomizing file list...')\n","random.shuffle(filez)\n","\n","TMIDIX.Tegridy_Any_Pickle_File_Writer(filez, '/content/Emotion2Music/MIDIs-File-List')"],"metadata":{"id":"DuVWtdDNcqKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 加载/重新加载MIDI文件列表\n","filez = TMIDIX.Tegridy_Any_Pickle_File_Reader('/content/Emotion2Music/MIDIs-File-List')"],"metadata":{"id":"DIPW5c2Jml85"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 数据处理"],"metadata":{"id":"Qp4VVkKBhiuR"}},{"cell_type":"code","source":["#@title 数据预处理耗时较长，可以根据自己实际情况选择在处理  20%，50%，100% 的时候停止此代码框，然后直接运行后面的代码块，或者直接下载以前处理好的数据进行训练即可。\n","# 使用TMIDIX MIDI处理器处理MIDI\n","\n","sorted_or_random_file_loading_order = False # Sorted order is NOT usually recommended\n","dataset_ratio = 1 # Change this if you need more data\n","\n","\n","print('TMIDIX MIDI Processor')\n","print('Starting up...')\n","###########\n","\n","files_count = 0\n","\n","gfiles = []\n","\n","melody_chords_f = []\n","\n","stats = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","print('Processing MIDI files. Please wait...')\n","for f in tqdm(filez[:int(len(filez) * dataset_ratio)]):\n","    try:\n","        fn = os.path.basename(f)\n","        fn1 = fn.split('.')[0]\n","\n","        #print('Loading MIDI file...')\n","        score = TMIDIX.midi2ms_score(open(f, 'rb').read())\n","\n","        events_matrix = []\n","\n","        itrack = 1\n","\n","        patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","        patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n","                     [24, 25, 26, 27, 28, 29, 30], # Guitar\n","                     [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n","                     [40, 41], # Violin\n","                     [42, 43], # Cello\n","                     [46], # Harp\n","                     [56, 57, 58, 59, 60], # Trumpet\n","                     [71, 72], # Clarinet\n","                     [73, 74, 75], # Flute\n","                     [-1], # Fake Drums\n","                     [52, 53], # Choir\n","                     [16, 17, 18, 19, 20] # Organ\n","                    ]\n","\n","        while itrack < len(score):\n","            for event in score[itrack]:         \n","                if event[0] == 'note' or event[0] == 'patch_change':\n","                    events_matrix.append(event)\n","            itrack += 1\n","\n","        events_matrix.sort(key=lambda x: x[1])\n","\n","        events_matrix1 = []\n","        for event in events_matrix:\n","                if event[0] == 'patch_change':\n","                    patches[event[2]] = event[3]\n","\n","                if event[0] == 'note':\n","                    event.extend([patches[event[3]]])\n","                    once = False\n","                    \n","                    for p in patch_map:\n","                        if event[6] in p and event[3] != 9: # Except the drums\n","                            event[3] = patch_map.index(p)\n","                            once = True\n","                            \n","                    if not once and event[3] != 9: # Except the drums\n","                        event[3] = 0 # All other instruments/patches channel\n","                        event[5] = max(80, event[5])\n","                        \n","                    if event[3] < 12: # We won't write chans 11-16 for now...\n","                        events_matrix1.append(event)\n","                        stats[event[3]] += 1\n","\n","        # Sorting...\n","        events_matrix1.sort(key=lambda x: (x[1], x[3]))\n","\n","        # recalculating timings\n","        for e in events_matrix1:\n","            e[1] = int(e[1] / 16)\n","            e[2] = int(e[2] / 32)\n","        \n","        # final processing...\n","\n","        pe = events_matrix1[0]\n","        for e in events_matrix1:\n","\n","            time = max(0, min(127, e[1]-pe[1]))\n","            dur = max(1, min(127, e[2]))\n","            cha = max(0, min(11, e[3]))\n","            ptc = max(1, min(127, e[4]))\n","            vel = max(19, min(127, e[5]))\n","\n","            div_vel = int(vel / 19)\n","\n","            chan_vel = (cha * 11) + div_vel\n","\n","            melody_chords_f.extend([chan_vel, time+128, dur+256, ptc+384])\n","\n","            pe = e\n","\n","        # Break between compositions\n","        melody_chords_f.extend([0, 127+128, 127+256, 0+384])\n","        melody_chords_f.extend([0, 127+128, 127+256, 0+384])\n","\n","        files_count += 1\n","\n","        if files_count % 4000 == 0:\n","          count = str(files_count)\n","          TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/Emotion2Music/INTS/ZMX_INTs_'+count)\n","          melody_chords_f = []\n","        \n","    except KeyboardInterrupt:\n","        print('Saving current progress and quitting...')\n","        break  \n","\n","    except:\n","        print('Bad MIDI:', f)\n","        continue\n","\n","count = str(files_count)\n","TMIDIX.Tegridy_Any_Pickle_File_Writer(melody_chords_f, '/content/INTS/ZMX_INTs_'+count)\n","\n","print('=' * 70)\n","        \n","print('Done!')   \n","print('=' * 70)\n","\n","print('Resulting Stats:')\n","print('=' * 70)\n","print('Total MIDI Files:', files_count)\n","print('=' * 70)\n","\n","print('Piano:', stats[0])\n","print('Guitar:', stats[1])\n","print('Bass:', stats[2])\n","print('Violin:', stats[3])\n","print('Cello:', stats[4])\n","print('Harp:', stats[5])\n","print('Trumpet:', stats[6])\n","print('Clarinet:', stats[7])\n","print('Flute:', stats[8])\n","print('Drums:', stats[9])\n","print('Choir:', stats[10])\n","print('Organ:', stats[11])\n","\n","print('=' * 70)"],"metadata":{"id":"xkHKfUoucXJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title *****下面的代码框可以下载提前处理好的数据集进行训练，有需要可以解开注释并运行*****\n","# # # 数据处理时间较长，也可以暂停处理，然后从我之前处理好的数据存储地址中下载。\n","# %cd /content/Emotion2Music\n","# !gdown https://drive.google.com/uc\\?id\\=1JvN3WDLTsOIQuGIUy1PDtbo4ZdY1aO2c   # 下载处理后的数据集\n","# !unzip INTS.zip                                # 解压\n",  "# !rm INTS.zip    # 删除压缩包" ,   " # %cd /content/Emotion2Music/INTS  # 进入INTS  \n " ,  "# !rm README.md  # 删除README.md"  , " # %cd /content/Emotion2Music  # 进入根目录  \n " "],"metadata":{"id":"m2qopRjSxd7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"id":"0826f622-2edc-4f09-9a01-58df049738d4","kernelId":""},"id":"t-jV34sBHX9z"},"outputs":[],"source":["#@title 导入数据\n","\n","#@markdown PLEASE NOTE: You will need at least 32GB RAM to load all files\n","\n","print('Processing the dataset...')\n","\n","dataset_addr = \"/content/Emotion2Music/INTS\"\n","# os.chdir(dataset_addr)\n","filez = list()\n","for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n","    filez += [os.path.join(dirpath, file) for file in filenames]\n","print('=' * 70)\n","\n","filez.sort()\n","\n","print('Processing MIDI files. Please wait...')\n","\n","train_data = torch.Tensor()\n","\n","for f in tqdm(filez):\n","  fn = f.split('.')[0]\n","  train_data = torch.cat((train_data, torch.Tensor(TMIDIX.Tegridy_Any_Pickle_File_Reader(fn))))\n","  print('Loaded file:', f)\n","\n","print('Done!')        \n","print('=' * 70)\n","        \n","print('Total INTs:', len(train_data))\n","print('=' * 70)"]},{"cell_type":"markdown","metadata":{"id":"-ye9rNzOHX90"},"source":["# 测试生成的INTs数据集。。。"]},{"cell_type":"code","source":["#@title 检测音乐数据 INTS\n","print('Sample INTs', train_data[:15])\n","\n","out = train_data[:160000].tolist()\n","\n","if len(out) != 0:\n","    \n","    song = out\n","    song_f = []\n","    time = 0\n","    dur = 0\n","    vel = 0\n","    pitch = 0\n","    channel = 0\n","\n","    son = []\n","\n","    song1 = []\n","\n","    for s in song:\n","      if s > 127:\n","        son.append(s)\n","\n","      else:\n","        if len(son) == 4:\n","          song1.append(son)\n","        son = []\n","        son.append(s)\n","    \n","    for s in song1:\n","\n","        channel = s[0] // 11\n","\n","        vel = (s[0] % 11) * 19\n","\n","        time += (s[1]-128) * 16\n","            \n","        dur = (s[2] - 256) * 32\n","        \n","        pitch = (s[3] - 384)\n","                                  \n","        song_f.append(['note', time, dur, channel, pitch, vel ])\n","\n","    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n","                                                        output_signature = 'ZMX',  \n","                                                        output_file_name = '/content/Emotion2Music/ZMX', \n","                                                        track_name='Project Los Angeles',\n","                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0],\n","                                                        number_of_ticks_per_quarter=500)\n","\n","    print('Done!')"],"metadata":{"id":"zppMJ8gA3L4K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 准备数据加载器"],"metadata":{"id":"eMrq1osy3_ZG"}},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"id":"53252e52-5e68-4e60-8e4d-a584667749a4","kernelId":""},"id":"lT0TyqUnpxu_"},"outputs":[],"source":["#@title Prep the dataloader\n","\n","SEQ_LEN = max_seq\n","\n","BATCH_SIZE = 1 # Change this to your specs\n","\n","# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n","\n","print('=' * 50)\n","print('Loading training data...')\n","\n","class MusicSamplerDataset(Dataset):\n","    def __init__(self, data, seq_len):\n","        super().__init__()\n","        self.data = data\n","        self.seq_len = seq_len\n","\n","    def __getitem__(self, index):\n","\n","        rand = secrets.randbelow((self.data.size(0)-(self.seq_len)) // (self.seq_len)) * (self.seq_len)\n","\n","        x = self.data[rand: rand + self.seq_len].long()\n","        trg = self.data[(rand+1): (rand+1) + self.seq_len].long()\n","        \n","        return x, trg\n","\n","    def __len__(self):\n","        return self.data.size(0) // self.seq_len\n","\n","train_dataset = MusicSamplerDataset(train_data, SEQ_LEN)\n","val_dataset   = MusicSamplerDataset(train_data, SEQ_LEN)\n","train_loader  = DataLoader(train_dataset, batch_size = BATCH_SIZE)\n","val_loader    = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n","\n","print('=' * 50)\n","print('Sample train dataset:', train_dataset[0])\n","print('Sample val dataset:', val_dataset[0])\n","print('=' * 50)\n","print('Train loader length:', len(train_loader))\n","print('Val loader length:', len(val_loader))\n","print('=' * 50)\n","print('Done! Enjoy! :)')\n","print('=' * 50)"]},{"cell_type":"markdown","metadata":{"id":"fkVqviDzJOrv"},"source":["# 三、开始训练"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"id":"4aa21407-a3e9-4ed2-9bf1-83c295482b8a","kernelId":""},"id":"2moo7uUmpxvC"},"outputs":[],"source":["#@title 训练\n","\n","DIC_SIZE = 512\n","\n","# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n","\n","config = GPTConfig(DIC_SIZE, \n","                   max_seq,\n","                   dim_feedforward=2048,\n","                   n_layer=24, \n","                   n_head=8, \n","                   n_embd=1024,\n","                   enable_rpr=True,\n","                   er_len=max_seq)\n","\n","# DO NOT FORGET TO ADJUST MODEL PARAMS IN GPT2RGAX module to your specs\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = GPT(config)\n","\n","model = nn.DataParallel(model)\n","\n","model.to(device)\n","\n","#=====\n","\n","init_step = 0\n","lr = 0.1 # Seems to work best\n","lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n","eval_loss_func = nn.CrossEntropyLoss(ignore_index=DIC_SIZE)\n","train_loss_func = eval_loss_func\n","\n","# opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n","\n","opt = Adam(model.parameters(), lr=lr) # Default optimizer settings work better on large datasets\n","\n","lr_scheduler = LambdaLR(opt, lr_stepper.step)\n","\n","\n","#===\n","\n","best_eval_acc        = 0.0\n","best_eval_acc_epoch  = -1\n","best_eval_loss       = float(\"inf\")\n","best_eval_loss_epoch = -1\n","best_acc_file = '/content/Emotion2Music/gpt2_rpr_acc.pth'\n","best_loss_file = '/content/Emotion2Music/gpt2_rpr_loss.pth'\n","loss_train, loss_val, acc_val = [], [], []\n","\n","for epoch in range(0, epochs):\n","    new_best = False\n","    \n","    loss = train(epoch+1, \n","                 model, train_loader, \n","                 train_loss_func, \n","                 opt, \n","                 lr_scheduler, \n","                 num_iters=-1, \n","                 save_checkpoint_steps=4000)\n","    \n","    loss_train.append(loss)\n","    \n","    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n","    loss_val.append(eval_loss)\n","    acc_val.append(eval_acc)\n","    \n","    if(eval_acc > best_eval_acc):\n","        best_eval_acc = eval_acc\n","        best_eval_acc_epoch  = epoch+1\n","        torch.save(model.state_dict(), best_acc_file)\n","        new_best = True\n","\n","    if(eval_loss < best_eval_loss):\n","        best_eval_loss       = eval_loss\n","        best_eval_loss_epoch = epoch+1\n","        torch.save(model.state_dict(), best_loss_file)\n","        new_best = True\n","    \n","    if(new_best):\n","        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n","        print(\"Best eval acc:\", best_eval_acc)\n","        print(\"\")\n","        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n","        print(\"Best eval loss:\", best_eval_loss)"]},{"cell_type":"markdown","metadata":{"id":"mdKFoeke9L7H"},"source":["# 四、模型保存"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"id":"73bea62d-084b-4f9a-9e55-2b34a932a7a4","kernelId":""},"id":"gqyDatHC9X1z"},"outputs":[],"source":["#@title 训练结束后将保存最好的模型\n","\n","print('Saving the model...')\n","full_path_to_model_checkpoint = \"/content/Best-Model.pth\" #@param {type:\"string\"}\n","torch.save(model.state_dict(), full_path_to_model_checkpoint)\n","print('Done!')"]},{"cell_type":"markdown","metadata":{"id":"YzCMd94Tu_gz"},"source":["# 恭喜您，已完成，现在可以用训练好的新模型进行推理了。"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/asigalov61/Euterpe/blob/main/Training-Code/Euterpe_Maker.ipynb","timestamp":1679543640578}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
