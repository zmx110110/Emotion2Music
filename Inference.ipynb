{"cells":[{"cell_type":"markdown","metadata":{"gradient":{"editing":false,"id":"fa0a611c-1803-42ae-bdf6-a49b5a4e781b","kernelId":""},"id":"4nMZZ3spwCvd"},"source":["# (一)准备工作"]},{"cell_type":"code","source":["# # 从github上下载代码。\n","!git clone https://github.com/zmx110110/Multi-Music-Transformer"],"metadata":{"id":"v-fye24OsYJ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 进入根目录\n","%cd /content/Multi-Music-Transformer"],"metadata":{"id":"Pr1jpw8WlwKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"gradient":{"editing":false,"id":"fa0a611c-1803-42ae-bdf6-a49b5a4e781b","kernelId":""},"id":"gOd93yV0sGd2"},"source":["# (二)安装运行环境"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"editing":false,"id":"39411b40-9e39-416e-8fe4-d40f733e7956","kernelId":""},"id":"lw-4aqV3sKQG"},"outputs":[],"source":["#@title nvidia-smi gpu check  (查看显卡情况)\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"editing":false,"id":"a1a45a91-d909-4fd4-b67a-5e16b971d179","kernelId":""},"id":"fX12Yquyuihc"},"outputs":[],"source":["#@title Install all dependencies (安装相关依赖,在Colab中每次运行都需要从新安装)\n","\n","!pip install einops\n","!pip install torch\n","!pip install torch-summary\n","\n","!pip install tqdm\n","!pip install matplotlib\n","\n","!apt install fluidsynth  # Pip does not work for some reason. Only apt works\n","!pip install midi2audio"]},{"cell_type":"code","execution_count":null,"metadata":{"gradient":{"editing":false,"id":"b8207b76-9514-4c07-95db-95a4742e52c5","kernelId":""},"id":"z7n9vnKmug1J"},"outputs":[],"source":["#@title Import all needed modules(导入需要的第三方库)\n","\n","print('Loading needed modules. Please wait...')\n","import os\n","import random\n","import copy\n","import math\n","from collections import OrderedDict\n","\n","from tqdm.notebook import tqdm\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torchsummary import summary\n","\n","print('Loading core modules...')\n","# os.chdir('/content/Perceiver-Music-Transformer')\n","# 这里需要使用新路径\n","os.chdir('/content/Multi-Music-Transformer')\n","import TMIDIX\n","\n","from zmx_ar_pytorch import PerceiverAR\n","from autoregressive_wrapper import AutoregressiveWrapper\n","\n","from midi2audio import FluidSynth\n","from IPython.display import Audio, display\n","\n","os.chdir('/content/Multi-Music-Transformer')\n","print('第三方库导入完成!')"]},{"cell_type":"markdown","metadata":{"id":"mdKFoeke9L7H"},"source":["# (三）下载训练好的权重"]},{"cell_type":"code","source":["# # 第一次运行需要下载,后面再运行就不需要下载了,总共1.3G。这里需要提前将权重上传到网盘，进行下载。\n","!gdown https://drive.google.com/uc\\?id\\=161z8svINvt_ShgKSBVLug5apjPT3Hixs"],"metadata":{"id":"dICiWco0JwU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Load/Reload the model (设置好预训练权重的路径) { vertical-output: true, form-width: \"400px\" }\n","\n","full_path_to_model_checkpoint = \"/content/Multi-Music-Transformer/Best-Model.pth\" #@param {type:\"string\"}\n","\n","print('Loading the model...')\n","# Load model\n","\n","# constants\n","\n","SEQ_LEN = 8192 * 4 # 32k\n","PREFIX_SEQ_LEN = (8192 * 4) - 1024\n","\n","model = PerceiverAR(\n","    num_tokens = 512,\n","    dim = 1024,\n","    depth = 24,\n","    heads = 16,\n","    dim_head = 64,\n","    cross_attn_dropout = 0.5,\n","    max_seq_len = SEQ_LEN,\n","    cross_attn_seq_len = PREFIX_SEQ_LEN\n",")\n","model = AutoregressiveWrapper(model)\n","model.cuda()\n","\n","state_dict = torch.load(full_path_to_model_checkpoint)\n","\n","model.load_state_dict(state_dict)\n","\n","model.eval()\n","\n","print('Done!')\n","\n","# Model stats\n","summary(model)"],"metadata":{"id":"-NLe35B0b9a5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# (四)进行推理"],"metadata":{"id":"-OY_5PjpVJQ7"}},{"cell_type":"code","source":["#@title Load Seed/Custom MIDI (传入一段引导音乐 , 并进行数据预处理 ) { vertical-output: true, form-width: \"400px\", display-mode: \"both\" }\n","full_path_to_custom_MIDI_file = \"/content/Multi-Music-Transformer/Input-Midi-1.mid\" #@param {type:\"string\"}\n","\n","print('Loading custom MIDI file...')\n","score = TMIDIX.midi2ms_score(open(full_path_to_custom_MIDI_file, 'rb').read())\n","\n","events_matrix = []\n","\n","itrack = 1\n","\n","#==================================================\n","\n","# Memories augmentator\n","\n","def augment(inputs):\n","\n","  outs = []\n","  outy = []\n","\n","  for i in range(1, 12):\n","\n","    out1 = []\n","    out2 = []\n","\n","    for j in range(0, len(inputs), 4):\n","      note = inputs[j:j+4]\n","\n","      if (note[0] // 11) != 9:\n","        aug_note1 = copy.deepcopy(note)\n","        aug_note2 = copy.deepcopy(note)\n","        aug_note1[3] += i\n","        aug_note2[3] -= i\n","      else:\n","        aug_note1 = note\n","        aug_note2 = note\n","\n","      out1.append(aug_note1)\n","      out2.append(aug_note2)\n","\n","    outs.append(out1[random.randint(0, int(len(out1) / 2)):random.randint(int(len(out1) / 2), len(out1))])\n","    outs.append(out2[random.randint(0, int(len(out2) / 2)):random.randint(int(len(out2) / 2), len(out2))])\n","\n","  for i in range(64):\n","    outy.extend(random.choice(outs))\n","\n","  outy1 = []\n","  for o in outy:\n","    outy1.extend(o)\n","\n","  return outy1\n","\n","#==================================================\n","\n","\n","patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","patch_map = [[0, 1, 2, 3, 4, 5, 6, 7], # Piano \n","              [24, 25, 26, 27, 28, 29, 30], # Guitar\n","              [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n","              [40, 41], # Violin\n","              [42, 43], # Cello\n","              [46], # Harp\n","              [56, 57, 58, 59, 60], # Trumpet\n","              [71, 72], # Clarinet\n","              [73, 74, 75], # Flute\n","              [-1], # Fake Drums\n","              [52, 53], # Choir\n","              [16, 17, 18, 19, 20] # Organ\n","            ]\n","\n","while itrack < len(score):\n","    for event in score[itrack]:         \n","        if event[0] == 'note' or event[0] == 'patch_change':\n","            events_matrix.append(event)\n","    itrack += 1\n","\n","events_matrix.sort(key=lambda x: x[1])\n","\n","events_matrix1 = []\n","for event in events_matrix:\n","        if event[0] == 'patch_change':\n","            patches[event[2]] = event[3]\n","\n","        if event[0] == 'note':\n","            event.extend([patches[event[3]]])\n","            once = False\n","            \n","            for p in patch_map:\n","                if event[6] in p and event[3] != 9: # Except the drums\n","                    event[3] = patch_map.index(p)\n","                    once = True\n","                    \n","            if not once and event[3] != 9: # Except the drums\n","                event[3] = 0 # All other instruments/patches channel\n","                event[5] = max(80, event[5])\n","                \n","            if event[3] < 12: # We won't write chans 11-16 for now...\n","                events_matrix1.append(event)\n","\n","# Sorting...\n","events_matrix1.sort(key=lambda x: (x[1], x[3]))\n","\n","# recalculating timings\n","for e in events_matrix1:\n","    e[1] = int(e[1] / 16)\n","    e[2] = int(e[2] / 32)\n","\n","# final processing...\n","\n","inputs = []\n","\n","melody = []\n","\n","melody_chords = []\n","\n","pe = events_matrix1[0]\n","for e in events_matrix1:\n","\n","    time = max(0, min(127, e[1]-pe[1]))\n","    dur = max(1, min(127, e[2]))\n","    cha = max(0, min(11, e[3]))\n","    ptc = max(1, min(127, e[4]))\n","    vel = max(19, min(127, e[5]))\n","\n","    div_vel = int(vel / 19)\n","\n","    chan_vel = (cha * 11) + div_vel\n","\n","    # Continuation / Inpainting\n","    inputs.extend([chan_vel, time+128, dur+256, ptc+384])\n","\n","    # Melody Orchestration\n","    if time != 0:\n","      if ptc < 60:\n","        ptc = (ptc % 12) + 60  \n","\n","      \n","      melody.extend([div_vel, time+128, dur+256, ptc+384])\n","\n","    # For future development\n","    melody_chords.append([time, dur, cha, ptc, vel])\n","\n","    pe = e\n","\n","# =================================\n","\n","out1 = inputs\n","\n","if len(out1) != 0:\n","    \n","    song = out1\n","    song_f = []\n","    time = 0\n","    dur = 0\n","    vel = 0\n","    pitch = 0\n","    channel = 0\n","    son = []\n","    song1 = []\n","\n","    for s in song:\n","      if s > 127:\n","        son.append(s)\n","\n","      else:\n","        if len(son) == 4:\n","          song1.append(son)\n","        son = []\n","        son.append(s)\n","    \n","    for s in song1:\n","      if s[0] > 0 and s[1] >= 128:\n","        if s[2] > 256 and s[3] > 384:\n","\n","          channel = s[0] // 11\n","\n","          vel = (s[0] % 11) * 19\n","\n","          time += (s[1]-128) * 16\n","      \n","          dur = (s[2] - 256) * 32\n","          \n","          pitch = (s[3] - 384)\n","                                    \n","          song_f.append(['note', time, dur, channel, pitch, vel ])\n","\n","    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n","                                                        output_signature = 'Perceiver',  \n","                                                        output_file_name = '/content/Perceiver-Music-Composition', \n","                                                        track_name='Project Los Angeles',\n","                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0],\n","                                                        number_of_ticks_per_quarter=500)\n","\n","    print('Done!')\n","\n","print('Displaying resulting composition...')\n","fname = '/content/Perceiver-Music-Composition'\n","\n","x = []\n","y =[]\n","c = []\n","\n","colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n","\n","for s in song_f:\n","  x.append(s[1] / 1000)\n","  y.append(s[4])\n","  c.append(colors[s[3]])\n","\n","FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n","display(Audio(str(fname + '.wav'), rate=16000))\n","\n","plt.figure(figsize=(14,5))\n","ax=plt.axes(title=fname)\n","ax.set_facecolor('black')\n","\n","plt.scatter(x,y, c=c)\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Pitch\")\n","plt.show()"],"metadata":{"id":"dJaRwK9bUKwG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 保存处理后的临时音乐\n","!mv  /content/Perceiver-Music-Composition.mid   /content/Temp_output.mid\n","!mv  /content/Perceiver-Music-Composition.wav   /content/Temp_output.wav"],"metadata":{"id":"2mA3V6D61aiQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# (五)扩展运用 "],"metadata":{"id":"aI0laUdWAkA3"}},{"cell_type":"code","source":["#@title Single Continuation Block Generator ( 模仿input进行生成 ) { form-width: \"400px\", display-mode: \"code\" }\n","\n","##@markdown NOTE: Play with the settings to get different results\n","number_of_prime_tokens = 512 #@param {type:\"slider\", min:128, max:512, step:16}\n","number_of_tokens_to_generate = 512 #@param {type:\"slider\", min:64, max:512, step:32}\n","temperature = 0.8 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","\n","#===================================================================\n","print('=' * 70)\n","print('Perceiver Music Model Continuation Generator')\n","print('=' * 70)\n","\n","print('Generation settings:')\n","print('=' * 70)\n","print('Number of prime tokens:', number_of_prime_tokens)\n","print('Number of tokens to generate:', number_of_tokens_to_generate)\n","print('Model temperature:', temperature)\n","\n","print('=' * 70)\n","print('Generating...')\n","\n","# inp = augment(inputs)\n","\n","inp = inputs * math.ceil((8192 * 4) / len(inputs))\n","\n","inp = inp[:(8192 * 4)]\n","\n","inp = inp[512+len(inputs[:number_of_prime_tokens]):] + inputs[:number_of_prime_tokens]\n","\n","inp1 = torch.LongTensor(inp).cuda()\n","\n","out = model.generate(inp1[None, ...], \n","                     number_of_tokens_to_generate, \n","                     temperature=temperature)  \n","\n","out1 = out.cpu().tolist()[0]\n","\n","if len(out1) != 0:\n","    \n","    song = inputs[:number_of_prime_tokens] + out1\n","    song_f = []\n","    time = 0\n","    dur = 0\n","    vel = 0\n","    pitch = 0\n","    channel = 0\n","    son = []\n","    song1 = []\n","\n","    for s in song:\n","      if s > 127:\n","        son.append(s)\n","\n","      else:\n","        if len(son) == 4:\n","          song1.append(son)\n","        son = []\n","        son.append(s)\n","    \n","    for s in song1:\n","      if s[0] > 0 and s[1] >= 128:\n","        if s[2] > 256 and s[3] > 384:\n","\n","          channel = s[0] // 11\n","\n","          vel = (s[0] % 11) * 19\n","\n","          time += (s[1]-128) * 16\n","      \n","          dur = (s[2] - 256) * 32\n","          \n","          pitch = (s[3] - 384)\n","                                    \n","          song_f.append(['note', time, dur, channel, pitch, vel ])\n","\n","    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n","                                                        output_signature = 'Perceiver',  \n","                                                        output_file_name = '/content/Perceiver-Music-Composition', \n","                                                        track_name='Project Los Angeles',\n","                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0],\n","                                                        number_of_ticks_per_quarter=500)\n","\n","    print('Done!')\n","\n","print('Displaying resulting composition...')\n","fname = '/content/Perceiver-Music-Composition'\n","\n","x = []\n","y =[]\n","c = []\n","\n","colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n","\n","for s in song_f:\n","  x.append(s[1] / 1000)\n","  y.append(s[4])\n","  c.append(colors[s[3]])\n","\n","FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n","display(Audio(str(fname + '.wav'), rate=16000))\n","\n","plt.figure(figsize=(14,5))\n","ax=plt.axes(title=fname)\n","ax.set_facecolor('black')\n","\n","plt.scatter(x,y, c=c)\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Pitch\")\n","plt.show()"],"metadata":{"id":"bAWBH-MudV3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 保存生成的中间音乐\n","!mv  /content/Perceiver-Music-Composition.mid   /content/Middle_output.mid\n","!mv  /content/Perceiver-Music-Composition.wav   /content/Middle_output.wav"],"metadata":{"id":"6Ca02eNb3G_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Auto-Continue Custom MIDI ( AI 自动生成 ) { form-width: \"400px\" }\n","\n","number_of_continuation_notes = 270 #@param {type:\"slider\", min:10, max:500, step:10}\n","number_of_prime_tokens = 512 #@param {type:\"slider\", min:128, max:512, step:16}\n","temperature = 0.8 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","\n","#===================================================================\n","print('=' * 70)\n","print('Perceiver Music Model Auto-Continuation Generator')\n","print('=' * 70)\n","\n","print('Generation settings:')\n","print('=' * 70)\n","print('Number of continuation notes:', number_of_continuation_notes)\n","print('Number of prime tokens:', number_of_prime_tokens)\n","print('Model temperature:', temperature)\n","\n","print('=' * 70)\n","print('Generating...')\n","\n","out2 = copy.deepcopy(inputs[:number_of_prime_tokens])\n","\n","# aug_inp = augment(inputs)\n","\n","for i in tqdm(range(number_of_continuation_notes)):\n","\n","  # inp = copy.deepcopy(aug_inp)\n","\n","  inp = inputs * math.ceil((8160 * 6) / len(inputs))\n","\n","  inp = inp[:(8192 * 4)]\n","\n","  inp = inp[512+len(out2):] + out2\n","\n","  inp = torch.LongTensor(inp).cuda()\n","\n","  out = model.generate(inp[None, ...], \n","                      4, \n","                      temperature=temperature)  \n","\n","  out1 = out.cpu().tolist()[0]\n","  out2.extend(out1)\n","\n","if len(out2) != 0:\n","    \n","    song = out2\n","    song_f = []\n","    time = 0\n","    dur = 0\n","    vel = 0\n","    pitch = 0\n","    channel = 0\n","    son = []\n","    song1 = []\n","\n","    for s in song:\n","      if s > 127:\n","        son.append(s)\n","\n","      else:\n","        if len(son) == 4:\n","          song1.append(son)\n","        son = []\n","        son.append(s)\n","    \n","    for s in song1:\n","      if s[0] > 0 and s[1] >= 128:\n","        if s[2] > 256 and s[3] > 384:\n","\n","          channel = s[0] // 11\n","\n","          vel = (s[0] % 11) * 19\n","\n","          time += (s[1]-128) * 16\n","      \n","          dur = (s[2] - 256) * 32\n","          \n","          pitch = (s[3] - 384)\n","                                    \n","          song_f.append(['note', time, dur, channel, pitch, vel ])\n","\n","    detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n","                                                        output_signature = 'Perceiver',  \n","                                                        output_file_name = '/content/Perceiver-Music-Composition', \n","                                                        track_name='Project Los Angeles',\n","                                                        list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0],\n","                                                        number_of_ticks_per_quarter=500)\n","\n","    print('Done!')\n","\n","print('Displaying resulting composition...')\n","fname = '/content/Perceiver-Music-Composition'\n","\n","x = []\n","y =[]\n","c = []\n","\n","colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n","\n","for s in song_f:\n","  x.append(s[1] / 1000)\n","  y.append(s[4])\n","  c.append(colors[s[3]])\n","\n","FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n","display(Audio(str(fname + '.wav'), rate=16000))\n","\n","plt.figure(figsize=(14,5))\n","ax=plt.axes(title=fname)\n","ax.set_facecolor('black')\n","\n","plt.scatter(x,y, c=c)\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Pitch\")\n","plt.show()"],"metadata":{"id":"TaH2748zN2oz","cellView":"code"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 保存生成的音乐\n","!mv  /content/Perceiver-Music-Composition.mid   /content/Final_output.mid\n","!mv  /content/Perceiver-Music-Composition.wav   /content/Final_output.wav"],"metadata":{"id":"XbzAQt6Z3aLE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YzCMd94Tu_gz"},"source":["# congratulations! 您运行成功 !"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/asigalov61/Perceiver-Music-Transformer/blob/main/Perceiver_Multi_Instrumental.ipynb","timestamp":1679275986895}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}